{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "First, we import all of the modules required for analysis.\n",
    "\n",
    "Note that we also use the `%gui qt5` magic. This sets the GUI backed to qt5, which is required for the image/results viewer we will use to visualize our results (`starfish.display()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt5\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from starfish import Experiment, display, Codebook, ExpressionMatrix, BinaryMaskCollection, LabelImage\n",
    "from starfish.image import Filter\n",
    "from starfish.spots import FindSpots, DecodeSpots, AssignTargets\n",
    "from starfish.types import Axes, Coordinates, Features, FunctionSource, TraceBuildingStrategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "First, we load the experiment from experiment files written in the the spacetx format.  The experiment file contains the locations to the files for loading them as well as relevant metadata (e.g., codebook, dataset shape).\n",
    "\n",
    "`./find_spots/make_find_spots_exp.py` was used to generate the experiment files.For details on constructing the experiment files, see the `make_experiment_file.ipynb` notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "exp = Experiment.from_json(\"./find_spots/experiment.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then get the first field of view. We select the images tagged `primary`, which are the images of the spots. Similary, we can access other types of images (e.g., nuclei or GFP) as defined by the experiment files. The image is returned as an `ImageStack` object which contains the array data as well as metadata (e.g., coordinates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = exp.fov().get_image('primary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing data\n",
    "We can view the image data using a [`napari`](https://www.github.com/napari/napari) viewer using the `display()` command. This will open a new window that allows us to explore the image. You can pan/zoom as you would in Google Maps. You can adjust the display parameters in the pallete on the left side of the window. You can scroll through different dimensions using the slider at the bottom of the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:07<00:00,  3.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x13ebdb630>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the image stack\n",
    "display(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the data\n",
    "Next, to improve the spot contrast, we filter the image. The general pattern when using starfish filters is to first instantiate the filter object with the filter properties as parameters. The `Filter` object can then be used to filter `ImageStack` objects. The same filter object can be used to filter multiple `ImageStack` objects. For example, if we want to create a gaussian high pass filter with sigma=3, we do the following\n",
    "\n",
    "```\n",
    "ghp = Filter.GaussianHighPass(sigma=3)\n",
    "```\n",
    "We can then filter the image using the `run()` method, which takes the `ImageStack` object to be filtered (first positional argument), a flag for verbose output (e.g., progress bars) and a flag for in place computation (i.e., if set to `True`, the filterd image replaces the original image.). In this example, we perform the apply gaussian high pass filter we instantiated above on the `im` `ImageStack` with the progress bars on (`verbose=True`) and we return the result as a new `ImageStack` object (`in_place=False`)\n",
    "```\n",
    "high_passed = ghp.run(im, verbose=True, in_place=False)\n",
    "```\n",
    "\n",
    "If we had a second `ImageStack` called `im2`, we could then filter `im2` with the same `ghp` object we previously used.\n",
    "```\n",
    "high_passed2 = ghp.run(im2, verbose=True, in_place=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 463.68it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 300.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter the image\n",
    "ghp = Filter.GaussianHighPass(sigma=3)\n",
    "high_passed = ghp.run(im, verbose=True, in_place=False)\n",
    "\n",
    "\n",
    "glp = Filter.GaussianLowPass(sigma=1)\n",
    "low_passed = glp.run(high_passed, in_place=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max intensity project the spots spots image\n",
    "mproj = Filter.Reduce((Axes.ZPLANE,), func='max', module=FunctionSource.np)\n",
    "mip = mproj.run(low_passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 70.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x10478e7b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(mip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting spots\n",
    "To detect spots, we will use the starfish `FindSpots.Blob` detector. This detector wraps the `skimage` `blob_log()` detector. For details on the parameters, see the docs [here](https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.blob_log). The detector components in `starfish` use the same pattern as the `Filter` components: (1) instantiate the component object with the detector parameters (2) use the object to detect spots on an `ImageStack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the spots\n",
    "p = FindSpots.BlobDetector(\n",
    "    min_sigma=1,\n",
    "    max_sigma=10,\n",
    "    num_sigma=10,\n",
    "    threshold=0.001,\n",
    "    measurement_type='mean',\n",
    ")\n",
    "\n",
    "spots = p.run(mip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign genes to spots\n",
    "Next, we assign a gene (target) to each detected spot. The `Codebook` object contains the mapping of (`round`, `channel`) combinations to target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the spots\n",
    "codebook = exp.codebook\n",
    "decoder = DecodeSpots.PerRoundMaxChannel(\n",
    "        codebook=codebook,\n",
    "        trace_building_strategy=TraceBuildingStrategies.SEQUENTIAL\n",
    ")\n",
    "\n",
    "decoded_intensities = decoder.run(spots=spots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x1040f4b70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(mip, decoded_intensities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell segmentation\n",
    "In order to assign detected targets to individual cells, we must first, segment the cells to determine their borders. `starfish` contains some basic cell segmentation tools, but we often use an external pipeline for segmentation (e.g., [CellProfiler](https://cellprofiler.org/) or [ilastik](https://www.ilastik.org/)). \n",
    "\n",
    "### Segmentation in external pipelines\n",
    "To segment cells in an external pipeline, we first write the relevant images to disk for processing. In this case, the cells expressed GFP throughout the cell body, so we will use that to segment the cells using CellProfiler. For details on the [CellProfiler](https://cellprofiler.org/) segmentation pipeline, see `./find_spots/segment_gfp.cpproj`. The pipeline outputs a label image in which each segmented cell body is assigned a unique integer label. If you wish to inspect the image, see `./find_spots/gfp_segmentation.tiff`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:08<00:00,  2.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.05it/s]\n",
      "/Users/kevin.yamauchi/Documents/InSituToolkit/.venv/lib/python3.6/site-packages/skimage/util/dtype.py:135: UserWarning: Possible precision loss when converting from float32 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "from InSituToolkit.analysis import save_stack\n",
    "\n",
    "# Save the GFP stack\n",
    "gfp = exp.fov().get_image('stain')\n",
    "gfp_mip = mproj.run(gfp)\n",
    "save_stack(gfp_mip, './find_spots/gfp.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading segmentaton results from external pipelines\n",
    "Note: this part of the `starfish` API is a work in progress and these steps will be consolidated in the near future.\n",
    "\n",
    "Once we generate a label image, we can load it into starfish and then use it to assign spots to cells. To load the image we:\n",
    "\n",
    "1. Load the label image generated by CellProfiler as a `np.ndarray` using `skimage.io` \n",
    "2. All images in `starfish` must have physical and pixel coordinates. Therefore, we get the coordinates from the source GFP image (i.e., the one that was saved to disk) to be attached to the resulting `LabelImage` object.\n",
    "3. We instantiate a `LabelImage` object containing the label image generated by CellProfiler and the physical/pixel coordinates of the image.\n",
    "4. Finally, we create the `BinaryMaskCollection` object which can then be used to assign spots to cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the label image generated in CellProfiler\n",
    "label_image = io.imread('./find_spots/gfp_segmentation.tiff')\n",
    "\n",
    "# Get the physical ticks from the original GFP image\n",
    "yc = gfp.xarray.yc.values\n",
    "xc = gfp.xarray.xc.values\n",
    "physical_ticks = {Coordinates.Y: yc, Coordinates.X:xc}\n",
    "\n",
    "# Get the pixel values from the original GFP image\n",
    "y = gfp.xarray.y.values\n",
    "x = gfp.xarray.x.values\n",
    "pixel_coords = {Axes.Y: y, Axes.X:x}\n",
    "\n",
    "# Create the label image\n",
    "label_im = LabelImage.from_label_array_and_ticks(\n",
    "    label_image,\n",
    "    pixel_coordinates=pixel_coords,\n",
    "    physical_coordinates=physical_ticks,\n",
    "    log=gfp_mip.log\n",
    ")\n",
    "# Create the mask collection\n",
    "masks = BinaryMaskCollection.from_label_image(label_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating cell x gene tables\n",
    "We assign spots to cells using `AssignTargets`. `AssignTargets` uses spot coordinates in `decoded_intensities` (`IntensityTable`) and the cell masks in `masks` (`BinaryMaskCollection`) to determine membership of each detected spot/target. The output is an `ExpressionMatrix` object which is a matrix where the each row is a cell, each column is a gene/target, and each element value is the number of counts of a given target in a given cell.\n",
    "\n",
    "Generally, the `ExpressionMatrix` is the interface between `starfish` analysis and other statistical analyses. The coordinates are for the centroid of the cell. The `cell_id` is the label index in the segmentation label image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.ExpressionMatrix 'expression_matrix' (cells: 6, genes: 1)>\n",
       "array([[ 2],\n",
       "       [30],\n",
       "       [ 1],\n",
       "       [ 6],\n",
       "       [ 8],\n",
       "       [ 3]])\n",
       "Coordinates:\n",
       "    x        (cells) float64 596.0 523.5 306.0 363.5 812.0 994.0\n",
       "    y        (cells) float64 603.5 710.0 740.0 757.0 742.5 550.0\n",
       "    z        (cells) float64 0.0 0.0 0.0 0.0 0.0 0.0\n",
       "    xc       (cells) float64 1.007e+05 1.007e+05 ... 1.007e+05 1.007e+05\n",
       "    yc       (cells) float64 4.324e+04 4.324e+04 ... 4.324e+04 4.324e+04\n",
       "    zc       (cells) float64 1.771e+03 1.771e+03 ... 1.771e+03 1.771e+03\n",
       "    area     (cells) float64 nan nan nan nan nan nan\n",
       "  * genes    (genes) object 'nan'\n",
       "    cell_id  (cells) object '0' '1' '2' '3' '4' 'nan'\n",
       "Dimensions without coordinates: cells"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "al = AssignTargets.Label()\n",
    "labeled = al.run(masks, decoded_intensities)\n",
    "cg = labeled.to_expression_matrix()\n",
    "cg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing the results\n",
    "We can view the segmentation masks and the spots all overlaid on the image as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = display(stack=mip, spots=decoded_intensities)\n",
    "viewer.add_labels(label_image);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

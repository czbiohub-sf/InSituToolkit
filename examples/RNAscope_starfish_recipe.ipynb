{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNAscope starfish recipe\n",
    "\n",
    "This recipe details all the preparation and ingredients necessary to cook up a starfish analysis pipeline for RNAscope experiments. It was written for users at CZBiohub and assumes the user has access to the imagingDB at CZBiohub.\n",
    "\n",
    "This recipe covers the following steps in cooking up a batch of starfish gumbo:\n",
    "\n",
    "- Accessing image files loaded onto the imaging server at CZBiohub\n",
    "- Creating starfish Experiment files from images accessed on the server\n",
    "- Working with starfish Experiment files and viewing images in napari\n",
    "- Image pre-processing for detecting flourescent spots\n",
    "- Identifying spots and overlaying them with the raw images in napari\n",
    "- Segmenting cells using starfish watershed algorithm\n",
    "- Constructing codebooks that assign targets to spots\n",
    "- Producing a target by cell matrix and other target statistics\n",
    "\n",
    "For questions or to request access to the imagingDB, contact recipe author @ andrew.cote@czbiohub.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing image files loaded onto the imaging server at CZBiohub\n",
    "\n",
    "To access images located on the server, you require login credentials for the database. These can be provided by Andrew Cote (andrew.cote@czbiohub.org), in addition to installing the requisite libraries (InSitu Toolkit @ https://github.com/czbiohub/InSituToolkit). \n",
    "\n",
    "The login credentials are a simple .json file which we use to authenticate your requests to the database. This can be stored locally on your laptop. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To start, we either need to know the dataset ids ahead of time, have a csv file with them (as might be \n",
    "# used to originaly upload the files from the microscope computer), or know the <id> \n",
    "# associated with the experiment files which we can then search in the database. \n",
    "\n",
    "# If we know the dataset id directly:\n",
    "dataset_id = 'GW-2019-12-22-04-45-00-0001'\n",
    "\n",
    "# Or even better, re-use the csv file we used on the microscope computer to upload the images \n",
    "import csv\n",
    "\n",
    "list_of_datasets = []\n",
    "with open('files_to_upload_example.csv') as csvfile:\n",
    "    read_csv = csv.reader(csvfile, delimiter = ',')\n",
    "    row_number = 0            # the top row of the csv file contains headers, which we want to ignore\n",
    "    for row in read_csv:\n",
    "        if row_number >= 1:\n",
    "            list_of_datasets.append(row[0])\n",
    "        row_number += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL DETOUR (This can be skipped if you use the built in InSituToolkit functions).\n",
    "\n",
    "# We can access all the metadata associated with the experiment by using database operations. \n",
    "# DatabaseOperations is a class in python that takes a unique dataset id in the constructor, and so must be re-made\n",
    "# each time you want to query metadata for a different experiment\n",
    "\n",
    "# A full tutorial for querying the database is given at \n",
    "# https://github.com/czbiohub/imagingDB/blob/master/notebooks/database_queries.ipynb\n",
    "\n",
    "from imaging_db.database.db_operations import DatabaseOperations\n",
    "import imaging_db.database.db_operations as db_ops\n",
    "import imaging_db.utils.db_utils as db_utils\n",
    "\n",
    "# Note: refer to your own db_credentials.json location stored locally\n",
    "db_credentials = '/Users/andrew.cote/Documents/db_credentials.json'  \n",
    "\n",
    "dbops = DatabaseOperations(dataset_id)\n",
    "credentials_str = db_utils.get_connection_str(db_credentials)\n",
    "with db_ops.session_scope(credentials_str) as session:\n",
    "    global_meta, frames_meta = dbops.get_frames_meta(session)\n",
    "    \n",
    "# global_meta and frames_meta now contained all the metadata associated with the whole experiment, and each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_idx</th>\n",
       "      <th>slice_idx</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>pos_idx</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>file_name</th>\n",
       "      <th>sha256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DAPI</td>\n",
       "      <td>im_c000_z000_t000_p000.png</td>\n",
       "      <td>128f5f59822b2ffd21bbbc2d2334725cb9bbcf5e397a0e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DAPI</td>\n",
       "      <td>im_c000_z000_t000_p001.png</td>\n",
       "      <td>2fd6dd6b7be297e3983e0c6ec4d56593d09053a0180aac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>DAPI</td>\n",
       "      <td>im_c000_z000_t000_p002.png</td>\n",
       "      <td>b209618f901315b1d0c2302d99614a29fd4b3d695cfdeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>DAPI</td>\n",
       "      <td>im_c000_z000_t000_p003.png</td>\n",
       "      <td>1ce609447626423306f00bb1a8285576b632a700580c1e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>DAPI</td>\n",
       "      <td>im_c000_z000_t000_p004.png</td>\n",
       "      <td>2dc5411557f1715a2758b1fe616b98f2d51ef8f0a42fb4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1645</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>Cy7</td>\n",
       "      <td>im_c004_z010_t000_p025.png</td>\n",
       "      <td>90087d8e4482bd333af89ccd5e643e31dd65cc093e983b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1646</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>Cy7</td>\n",
       "      <td>im_c004_z010_t000_p026.png</td>\n",
       "      <td>560497689112cb4dc895409484909bca04a383391f95d8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1647</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>Cy7</td>\n",
       "      <td>im_c004_z010_t000_p027.png</td>\n",
       "      <td>e2ecd12486be3b768fb296f4235ab646fe3a28f17b0e68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1648</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>Cy7</td>\n",
       "      <td>im_c004_z010_t000_p028.png</td>\n",
       "      <td>a0b7ff61bd6310e3d2d7b66032e8e8f985fba2b158a9f0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1649</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>Cy7</td>\n",
       "      <td>im_c004_z010_t000_p029.png</td>\n",
       "      <td>ec8d2bb181b1717c1482f638baaed0e4124208497db1ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1650 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      channel_idx  slice_idx  time_idx  pos_idx channel_name  \\\n",
       "0               0          0         0        0         DAPI   \n",
       "1               0          0         0        1         DAPI   \n",
       "2               0          0         0        2         DAPI   \n",
       "3               0          0         0        3         DAPI   \n",
       "4               0          0         0        4         DAPI   \n",
       "...           ...        ...       ...      ...          ...   \n",
       "1645            4         10         0       25          Cy7   \n",
       "1646            4         10         0       26          Cy7   \n",
       "1647            4         10         0       27          Cy7   \n",
       "1648            4         10         0       28          Cy7   \n",
       "1649            4         10         0       29          Cy7   \n",
       "\n",
       "                       file_name  \\\n",
       "0     im_c000_z000_t000_p000.png   \n",
       "1     im_c000_z000_t000_p001.png   \n",
       "2     im_c000_z000_t000_p002.png   \n",
       "3     im_c000_z000_t000_p003.png   \n",
       "4     im_c000_z000_t000_p004.png   \n",
       "...                          ...   \n",
       "1645  im_c004_z010_t000_p025.png   \n",
       "1646  im_c004_z010_t000_p026.png   \n",
       "1647  im_c004_z010_t000_p027.png   \n",
       "1648  im_c004_z010_t000_p028.png   \n",
       "1649  im_c004_z010_t000_p029.png   \n",
       "\n",
       "                                                 sha256  \n",
       "0     128f5f59822b2ffd21bbbc2d2334725cb9bbcf5e397a0e...  \n",
       "1     2fd6dd6b7be297e3983e0c6ec4d56593d09053a0180aac...  \n",
       "2     b209618f901315b1d0c2302d99614a29fd4b3d695cfdeb...  \n",
       "3     1ce609447626423306f00bb1a8285576b632a700580c1e...  \n",
       "4     2dc5411557f1715a2758b1fe616b98f2d51ef8f0a42fb4...  \n",
       "...                                                 ...  \n",
       "1645  90087d8e4482bd333af89ccd5e643e31dd65cc093e983b...  \n",
       "1646  560497689112cb4dc895409484909bca04a383391f95d8...  \n",
       "1647  e2ecd12486be3b768fb296f4235ab646fe3a28f17b0e68...  \n",
       "1648  a0b7ff61bd6310e3d2d7b66032e8e8f985fba2b158a9f0...  \n",
       "1649  ec8d2bb181b1717c1482f638baaed0e4124208497db1ad...  \n",
       "\n",
       "[1650 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating \"starfish experiment\" files from images accessed on the server\n",
    "\n",
    "Once we are able to access the raw image files on the database, we'd like to create starfish 'Experiment' objects to simplify the later analysis. Each Experiment is a self-contained module that has all raw image data, as well as metadata. Subsequent analysis in this notebook is restricted to a single experiment, but can be generalized to many experiments as all Experiment objects have the same interface / methods. \n",
    "\n",
    "An Experiment object is essentially a series of .json files that contain metadata which reference the raw images on the database. Therefore they are fairly small in size and can be created and stored locally, ideally in a './experiments/' folder for ease of navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directories to contain experiment files\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "experiment_path = cwd + '/experiments/' + dataset_id + '/'\n",
    "\n",
    "if not os.path.exists(experiment_path):\n",
    "    os.mkdir(experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create experiment files we need to find a few key pieces of metadata: positions, and channels \n",
    "# these could be retrieved through the above database queries but InSituToolkit exposes a few useful methods\n",
    "\n",
    "from InSituToolkit.imaging_database import write_experiment, get_positions, get_channels, search_ids\n",
    "from slicedimage import ImageFormat\n",
    "db_credentials = '/Users/andrew.cote/Documents/db_credentials.json' \n",
    "\n",
    "\n",
    "# search the database for dataset id's that contain a certain string\n",
    "set_of_datasets = search_ids(db_credentials, 'GW')\n",
    "\n",
    "# find all the microscope positions for a dataset in the database\n",
    "positions = get_positions(db_credentials, dataset_id)\n",
    "\n",
    "# find the filters and channels used\n",
    "# Note: it is good practice to inspect the channels variable manually to double check we are not mis-assigning channels\n",
    "channels = get_channels(db_credentials, dataset_id)\n",
    "\n",
    "nuc_channel = [channels[0]]\n",
    "stain_channel = [channels[1]]\n",
    "spot_channel = [channels[2], channels[3], channels[4]]\n",
    "\n",
    "# Note: the dataset_id MUST be contained in a list. Multiple dataset ID's could be written to the same experiment\n",
    "# if the channels are common among them. \n",
    "\n",
    "write_experiment(db_credentials, experiment_path, [dataset_id], \n",
    "                spot_channels = spot_channel, \\\n",
    "                nuc_channels = nuc_channel, \\\n",
    "                stain_channels = stain_channel, \\\n",
    "                positions = positions, \\\n",
    "                img_format = 'PNG')   # By default the InSituScope saves as .PNG files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL DETOUR: For a larger number of experiments with the same <id>, we could generalize this to:\n",
    "list_of_datasets = []\n",
    "list_of_positions = []\n",
    "list_of_channels = []\n",
    "for dataset_id in search_ids(db_credentials, 'GW'):\n",
    "    list_of_datasets.append(dataset_id)\n",
    "    list_of_positions.append(get_positions(db_credentials, dataset_id))\n",
    "    list_of_channels.append(get_channels(db_credentials, dataset_id))\n",
    "    \n",
    "# ... include the above code for creating directories and experiments (ommitted here for run-ability of this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Starfish Experiment files and viewing images in napari\n",
    "\n",
    "Napari is a viewer that is built around manipulating high-dimensional image files, for example, the 5D image file from a starfish Experiment, where the dimensions are (Round, Channel, Z, X, Y). It also has convenient options for viewing spots, stains, and segmentation masks on top of raw image files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/napari/__init__.py:27: UserWarning: \n",
      "    napari was tested with QT library `>=5.12.3`.\n",
      "    The version installed is 5.9.6. Please report any issues with this\n",
      "    specific QT version at https://github.com/Napari/napari/issues.\n",
      "    \n",
      "  warn(message=warn_message)\n"
     ]
    }
   ],
   "source": [
    "# note: the below command '%gui qt5' is only required in a jupyter notebook. In a standalone script, starfish.display \n",
    "# will open the napari window by default. \n",
    "\n",
    "%gui qt5\n",
    "from starfish import Experiment, FieldOfView, display\n",
    "import napari\n",
    "\n",
    "exp = Experiment.from_json(experiment_path + 'experiment.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment objects are dicts which hold all the image data for each microscope location, or fov. A likely use-case\n",
    "# is to perform the same image processing technique to all fov's in an experiment. We can collect all keys as:\n",
    "\n",
    "list_of_keys = []\n",
    "\n",
    "for key in exp.keys():\n",
    "    list_of_keys.append(key)\n",
    "\n",
    "# a fov has multiple types of images depending on the data that was uploaded, for example, nuclei, or stain\n",
    "# starfish by default returns a ImageStack Iterator object, which necessitates the call of 'next()' to \n",
    "# retrieve the actual image stack\n",
    "\n",
    "fov = exp['fov_000']\n",
    "\n",
    "sample_primary = next(fov.get_images('primary'))\n",
    "sample_nuclei = next(fov.get_images('nuclei'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FOVS is 30\n",
      "The first two are ['fov_000', 'fov_001']\n"
     ]
    }
   ],
   "source": [
    "print('Number of FOVS is ' + str(len(list_of_keys)))\n",
    "print('The first two are ' + (str(list_of_keys[0:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:08<00:00,  4.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:03<00:00,  3.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x11b289310>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To display multiple images in the same viewer, assign a variable name to the display(ImageStack) command\n",
    "\n",
    "example_viewer = display(sample_primary)\n",
    "display(sample_nuclei, viewer = example_viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Image Processing in Starfish\n",
    "\n",
    "Starfish has numerous built-in methods to do some simple image processing tasks, including:\n",
    "- image registration (learning and applying transforms between successive imaging rounds)\n",
    "- projection (reducing the dimensionality of the images, e.g. flattening the z-stack)\n",
    "- filtering (high-pass or low-pass filtering to help isolate spots)\n",
    "\n",
    "A more detailed list can be found here: https://spacetx-starfish.readthedocs.io/en/stable/api/image/index.html\n",
    "For this example of an RNAscope workflow, since we are only imaging across "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:07<00:00,  4.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# A common step is to project all images along the z-dimension by the maximum pixel value, as this captures the \n",
    "# information from the best in-focus plane. \n",
    "\n",
    "# The ImageStack.reduce() function can project along any dimension desired, ZPLANE, ROUNDS, etc. \n",
    "\n",
    "from starfish.types import Axes, Coordinates, Features, FunctionSource, TraceBuildingStrategies\n",
    "from starfish.image import Filter, Segment\n",
    "\n",
    "\n",
    "projected_z_stacks = []\n",
    "\n",
    "for key in list_of_keys[0:1]:  # Change the indices to iterate over more fovs if desired\n",
    "    img_raw = next(exp[key].get_images('primary'))\n",
    "    img_proj_z = img_raw.reduce({Axes.ZPLANE}, func='max')   \n",
    "    projected_z_stacks.append(img_proj_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 73.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 112.00it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 54.76it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 89.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'band-passed z stack' at 0x1c57656810>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To isolate features that are 'spot like,' we can run a Gaussian high-pass then low-pass filter, i.e. a bandpass\n",
    "# filter. This helps reduce cellular autoflourescence, which is usually low-frequency (i.e. broad and smeared out)\n",
    "\n",
    "single_z_stack = projected_z_stacks[0]\n",
    "\n",
    "# Bandpass filter on features that are Gaussian spot-like\n",
    "ghp = Filter.GaussianHighPass(sigma=5)\n",
    "high_passed = ghp.run(single_z_stack, verbose=True, in_place=False)\n",
    "\n",
    "glp = Filter.GaussianLowPass(sigma=1)\n",
    "band_passed = glp.run(high_passed, verbose=True, in_place=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'top-hat filtered 2px' at 0x1c6cff31d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the results of the bandpass filter. Notice that for one of the views available in napari, the background\n",
    "# cell autofluourescence is greatly reduced. \n",
    "filtered_viewer = napari.Viewer()\n",
    "filtered_viewer.add_image(single_z_stack.xarray.values, name='single z stack')\n",
    "filtered_viewer.add_image(band_passed.xarray.values, name='band-passed z stack')\n",
    "\n",
    "\n",
    "# Note that in this sample there is still large flourescent bands that we may want to eliminate. We can do so\n",
    "# using a white top-hat filter, which will only let through features smaller than the radius specified. \n",
    "\n",
    "masking_radius = 2 # in pixels\n",
    "filt = Filter.WhiteTophat(masking_radius, is_volume=False)\n",
    "tophat_filtered = filt.run(band_passed, in_place=False)\n",
    "filtered_viewer.add_image(tophat_filtered.xarray.values, name='top-hat filtered 2px')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spot-finding\n",
    "\n",
    "After we've filtered the images to remove background fluourescence we can now identify spots corresponding to the flourescent molecules in the study. starfish makes this relatively straightfoward through a built-in spot-finding method. \n",
    "\n",
    "Further documentation can be found at https://spacetx-starfish.readthedocs.io/en/mcai-watershedtutorial/api/spots/index.html#module-starfish.spots.FindSpots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starfish.spots import FindSpots, DecodeSpots, AssignTargets\n",
    "from starfish.types import TraceBuildingStrategies\n",
    "from starfish.core.spots.DecodeSpots.trace_builders import build_traces_sequential\n",
    "\n",
    "# these parameters can be adjusted if spots are not found or large features are identified as spots that shouldnt be\n",
    "\n",
    "bd = FindSpots.BlobDetector(\n",
    "    min_sigma = 1,\n",
    "    max_sigma = 10,\n",
    "    num_sigma = 30,\n",
    "    threshold = 0.01,\n",
    "    measurement_type = 'mean')\n",
    "\n",
    "spots = bd.run(image_stack = band_passed)\n",
    "\n",
    "# viewing spots directly is not part of the usual starfish analysis procedure,\n",
    "# therefore we need to use build_traces_sequential to covert the spots into an intensity table\n",
    "# which is viewable in the native display. \n",
    "intensity_table = build_traces_sequential(spots)\n",
    "viewer = display(stack = single_z_stack, spots=intensity_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenting cells using starfish watershed algorithm\n",
    "\n",
    "Watershed algorithm is a method of segmenting cells based on changes in pixel intensity, by grouping pixels into 'basins,' taking as a starting point the nuclei of each cell. A more thorough explanation of the method as used by starfish can be found here:https://spacetx-starfish.readthedocs.io/en/mcai-watershedtutorial/creating_an_image_processing_pipeline/tutorials/exec_watershed_segmentation.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starfish.image import Segment\n",
    "\n",
    "nuclei = next(fov.get_images(\"nuclei\"))\n",
    "stain = next(fov.get_images(\"stain\"))\n",
    "primary = next(fov.get_images(FieldOfView.PRIMARY_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:03<00:00,  2.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:08<00:00,  3.90it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:03<00:00,  2.79it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 50.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 79.43it/s]\n"
     ]
    }
   ],
   "source": [
    "nuclei = nuclei.reduce({Axes.ZPLANE}, func='max')\n",
    "primary = primary.reduce({Axes.ZPLANE}, func='max')\n",
    "stain = stain.reduce({Axes.ZPLANE}, func='max')\n",
    "\n",
    "# NOTE: TopHat filtering is not strictly necessary for segmentation but is optional if desired\n",
    "# for Watershed segmenting, it helps to apply a TopHat filter to more clearly isolate the nuclei against background\n",
    "# fluorescence, and also eliminate blur from out-of-focus plane. (Note we still projected along Z-axis to capture cells\n",
    "# in different planes of focus, but wish to eliminate the out-of-focus components)\n",
    "\n",
    "masking_radius = 15\n",
    "filt = filt = Filter.WhiteTophat(masking_radius, is_volume=False)\n",
    "nuclei_filt = filt.run(nuclei, in_place=False)\n",
    "stain_filt  = filt.run(stain,  in_place=False)\n",
    "\n",
    "# Segmenting is a process that can be fine-tuned by varying the filter masking_radius and thresholds below. It is smart\n",
    "# to compare results in the napari viewer and iterate to get the desired result. \n",
    "\n",
    "dapi_thresh = 0.18\n",
    "stain_thresh = 0.22\n",
    "min_dist = 7\n",
    "\n",
    "# Lets try two segmentations with different parameters and see how they compare\n",
    "seg = Segment.Watershed(\n",
    "    nuclei_threshold = dapi_thresh,\n",
    "    input_threshold  = stain_thresh,\n",
    "    min_distance     = min_dist)\n",
    "\n",
    "seg2 = Segment.Watershed(\n",
    "    nuclei_threshold = dapi_thresh*3/2,\n",
    "    input_threshold  = stain_thresh*2/3,\n",
    "    min_distance     = min_dist-2)  # min distance must be specified in pixels, so no floats!\n",
    "\n",
    "mask = seg.run(stain_filt, nuclei_filt)\n",
    "mask2 = seg2.run(stain_filt, nuclei_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/starfish/core/morphology/object/binary_mask/expand.py:50: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  fill_value_array = result_array[selector]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/starfish/core/morphology/object/binary_mask/expand.py:52: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result_array[selector] = fill_value_array\n",
      "/opt/anaconda3/lib/python3.7/site-packages/starfish/core/morphology/object/binary_mask/expand.py:50: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  fill_value_array = result_array[selector]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/starfish/core/morphology/object/binary_mask/expand.py:52: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result_array[selector] = fill_value_array\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'nuclei' at 0x1ca6531a50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way of constructing a napari viewer and comparing results, assigning labels for ease of keeping track\n",
    "\n",
    "disp = napari.Viewer()\n",
    "\n",
    "disp.add_image(mask.to_label_image().xarray.values, name='mask')\n",
    "disp.add_image(mask2.to_label_image().xarray.values, name='mask2')\n",
    "disp.add_image(nuclei_filt.xarray.values, name='nuclei', colormap='red')\n",
    "\n",
    "# Observe that the second mask has much sparser and far fewer nuclei than the first mask,\n",
    "# as a result of lowering the input_threshold parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codebook Construction\n",
    "\n",
    "We now assign targets to the spots found in the previous section. For RNAscope applications, each target flouresces in just one Round/Channel pair, in contrast to in-situ sequencing in which a single target will have different channels over multiple rounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starfish import Codebook\n",
    "from starfish.types import Axes, Coordinates, Features\n",
    "\n",
    "# RNAscope codebooks should only have one round value for each target gene, \n",
    "# as they are imaged in a single round\n",
    "\n",
    "\n",
    "codebook_RNAscope = [\n",
    "      {\n",
    "          Features.CODEWORD: [\n",
    "              {Axes.ROUND.value: 0, Axes.CH.value: 0, Features.CODE_VALUE: 1},\n",
    "          ],\n",
    "          Features.TARGET: \"example_gene1\"\n",
    "      },\n",
    "      {\n",
    "          Features.CODEWORD: [\n",
    "              {Axes.ROUND.value: 0, Axes.CH.value: 1, Features.CODE_VALUE: 1},\n",
    "          ],\n",
    "          Features.TARGET: \"example_gene2\"\n",
    "      },\n",
    "      {\n",
    "          Features.CODEWORD: [\n",
    "              {Axes.ROUND.value: 0, Axes.CH.value: 2, Features.CODE_VALUE: 1},\n",
    "          ],\n",
    "          Features.TARGET: \"example_gene3\"\n",
    "      },\n",
    "  ]\n",
    "\n",
    "\n",
    "# we finish the codebook construction by calling the constructor for the starfish Codebook object. \n",
    "codebook = Codebook.from_code_array(codebook_RNAscope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning spots to cells\n",
    "\n",
    "With a codebook of target genes, a segmented image of the cells/nuclei, and a filtered image of spots, we are now ready to bring everything together to produce a cell x gene count matrix. \n",
    "\n",
    "First we decode the spots according to the codebook and a chosen trace building strategy, which translates from a items which are one or more (round, channel) pairs and converts them to targets in a codebook. \n",
    "\n",
    "Then we assign these targets to the cells segmented previously, and output the desired cell x gene table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for decoding spots, there are multiple different trace-building strategies which inform\n",
    "# how starfish assigns the targets to given spots. For a single round of spots\n",
    "# such as RNAscope, SEQUENTIAL is the best strategy and others may throw errors. \n",
    "\n",
    "spot_decoder = DecodeSpots.PerRoundMaxChannel(codebook = codebook,\n",
    "                                             trace_building_strategy = TraceBuildingStrategies.SEQUENTIAL)\n",
    "\n",
    "decoded_intensities = spot_decoder.run(spots = spots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = AssignTargets.Label()\n",
    "labeled = al.run(mask, decoded_intensities)\n",
    "cg = labeled.to_expression_matrix()\n",
    "cg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

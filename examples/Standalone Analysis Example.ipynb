{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standalone analysis\n",
    "\n",
    "This notebook details a standalone analysis of a single experiment, but can be readily extended to multiple experiment files as necessary. It details the following common steps in setting up an image processing pipeline:\n",
    "\n",
    "- Accessing image files loaded onto the imaging server at CZBiohub\n",
    "- Creating starfish Experiment files from images accessed on the server\n",
    "- Working with Experiment files and viewing images in napari\n",
    "- Segmenting cells using starfish watershed algorithm\n",
    "- Image pre-processing for detecting flourescent spots\n",
    "- Identifying spots and overlaying them with the raw images in napari\n",
    "- Constructing codebooks that assign targets to spots\n",
    "- Producing a target by cell matrix and other target statistics\n",
    "\n",
    "Questions? contact author @ andrew.cote@czbiohub.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing image files loaded onto the imaging server at CZBiohub\n",
    "\n",
    "To access images located on the server, you require login credentials for the database. These can be provided by Andrew Cote (andrew.cote@czbiohub.org), in addition to installing the requisite libraries (InSitu Toolkit @ https://github.com/czbiohub/InSituToolkit). \n",
    "\n",
    "The login credentials are a simple .json file which we use to authenticate your requests to the database. This can be stored locally on your laptop. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start, we either need to know the dataset ids ahead of time, have a csv file with them (as might be \n",
    "# used to originaly upload the files from the microscope computer), or know the <id> \n",
    "# associated with the experiment files which we can then search in the database. \n",
    "\n",
    "# If we know the dataset id directly:\n",
    "dataset_id = 'GW-2019-12-22-04-45-00-0002'\n",
    "\n",
    "# Or even better, re-use the csv file we used on the microscope computer to upload the images \n",
    "import csv\n",
    "\n",
    "list_of_datasets = []\n",
    "with open('files_to_upload_example.csv') as csvfile:\n",
    "    read_csv = csv.reader(csvfile, delimiter = ',')\n",
    "    row_number = 0            # the top row of the csv file contains headers, which we want to ignore\n",
    "    for row in read_csv:\n",
    "        if row_number >= 1:\n",
    "            list_of_datasets.append(row[0])\n",
    "        row_number += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL DETOUR (This can be skipped if you use the built in InSituToolkit functions).\n",
    "\n",
    "# We can access all the metadata associated with the experiment by using database operations. \n",
    "# DatabaseOperations is a class in python that takes a unique dataset id in the constructor, and so must be re-made\n",
    "# each time you want to query metadata for a different experiment\n",
    "\n",
    "# A full tutorial for querying the database is given at \n",
    "# https://github.com/czbiohub/imagingDB/blob/master/notebooks/database_queries.ipynb\n",
    "\n",
    "from imaging_db.database.db_operations import DatabaseOperations\n",
    "import imaging_db.database.db_operations as db_ops\n",
    "import imaging_db.utils.db_utils as db_utils\n",
    "\n",
    "# Note: refer to your own db_credentials.json location stored locally\n",
    "db_credentials = '/Users/andrew.cote/Documents/db_credentials.json'  \n",
    "\n",
    "dbops = DatabaseOperations(dataset_id)\n",
    "credentials_str = db_utils.get_connection_str(db_credentials)\n",
    "with db_ops.session_scope(credentials_str) as session:\n",
    "    global_meta, frames_meta = dbops.get_frames_meta(session)\n",
    "    \n",
    "# global_meta and frames_meta now contained all the metadata associated with the whole experiment, and each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_idx</th>\n",
       "      <th>slice_idx</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>pos_idx</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>file_name</th>\n",
       "      <th>sha256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DAPI</td>\n",
       "      <td>im_c000_z000_t000_p000.tiff</td>\n",
       "      <td>128f5f59822b2ffd21bbbc2d2334725cb9bbcf5e397a0e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DAPI</td>\n",
       "      <td>im_c000_z000_t000_p001.tiff</td>\n",
       "      <td>2fd6dd6b7be297e3983e0c6ec4d56593d09053a0180aac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>DAPI</td>\n",
       "      <td>im_c000_z000_t000_p002.tiff</td>\n",
       "      <td>b209618f901315b1d0c2302d99614a29fd4b3d695cfdeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>DAPI</td>\n",
       "      <td>im_c000_z000_t000_p003.tiff</td>\n",
       "      <td>1ce609447626423306f00bb1a8285576b632a700580c1e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>DAPI</td>\n",
       "      <td>im_c000_z000_t000_p004.tiff</td>\n",
       "      <td>2dc5411557f1715a2758b1fe616b98f2d51ef8f0a42fb4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1645</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>Cy7</td>\n",
       "      <td>im_c004_z010_t000_p025.tiff</td>\n",
       "      <td>90087d8e4482bd333af89ccd5e643e31dd65cc093e983b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1646</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>Cy7</td>\n",
       "      <td>im_c004_z010_t000_p026.tiff</td>\n",
       "      <td>560497689112cb4dc895409484909bca04a383391f95d8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1647</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>Cy7</td>\n",
       "      <td>im_c004_z010_t000_p027.tiff</td>\n",
       "      <td>e2ecd12486be3b768fb296f4235ab646fe3a28f17b0e68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1648</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>Cy7</td>\n",
       "      <td>im_c004_z010_t000_p028.tiff</td>\n",
       "      <td>a0b7ff61bd6310e3d2d7b66032e8e8f985fba2b158a9f0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1649</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>Cy7</td>\n",
       "      <td>im_c004_z010_t000_p029.tiff</td>\n",
       "      <td>ec8d2bb181b1717c1482f638baaed0e4124208497db1ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1650 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      channel_idx  slice_idx  time_idx  pos_idx channel_name  \\\n",
       "0               0          0         0        0         DAPI   \n",
       "1               0          0         0        1         DAPI   \n",
       "2               0          0         0        2         DAPI   \n",
       "3               0          0         0        3         DAPI   \n",
       "4               0          0         0        4         DAPI   \n",
       "...           ...        ...       ...      ...          ...   \n",
       "1645            4         10         0       25          Cy7   \n",
       "1646            4         10         0       26          Cy7   \n",
       "1647            4         10         0       27          Cy7   \n",
       "1648            4         10         0       28          Cy7   \n",
       "1649            4         10         0       29          Cy7   \n",
       "\n",
       "                        file_name  \\\n",
       "0     im_c000_z000_t000_p000.tiff   \n",
       "1     im_c000_z000_t000_p001.tiff   \n",
       "2     im_c000_z000_t000_p002.tiff   \n",
       "3     im_c000_z000_t000_p003.tiff   \n",
       "4     im_c000_z000_t000_p004.tiff   \n",
       "...                           ...   \n",
       "1645  im_c004_z010_t000_p025.tiff   \n",
       "1646  im_c004_z010_t000_p026.tiff   \n",
       "1647  im_c004_z010_t000_p027.tiff   \n",
       "1648  im_c004_z010_t000_p028.tiff   \n",
       "1649  im_c004_z010_t000_p029.tiff   \n",
       "\n",
       "                                                 sha256  \n",
       "0     128f5f59822b2ffd21bbbc2d2334725cb9bbcf5e397a0e...  \n",
       "1     2fd6dd6b7be297e3983e0c6ec4d56593d09053a0180aac...  \n",
       "2     b209618f901315b1d0c2302d99614a29fd4b3d695cfdeb...  \n",
       "3     1ce609447626423306f00bb1a8285576b632a700580c1e...  \n",
       "4     2dc5411557f1715a2758b1fe616b98f2d51ef8f0a42fb4...  \n",
       "...                                                 ...  \n",
       "1645  90087d8e4482bd333af89ccd5e643e31dd65cc093e983b...  \n",
       "1646  560497689112cb4dc895409484909bca04a383391f95d8...  \n",
       "1647  e2ecd12486be3b768fb296f4235ab646fe3a28f17b0e68...  \n",
       "1648  a0b7ff61bd6310e3d2d7b66032e8e8f985fba2b158a9f0...  \n",
       "1649  ec8d2bb181b1717c1482f638baaed0e4124208497db1ad...  \n",
       "\n",
       "[1650 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating \"starfish experiment\" files from images accessed on the server\n",
    "\n",
    "Once we are able to access the raw image files on the database, we'd like to create starfish 'Experiment' objects to simplify the later analysis. Each Experiment is a self-contained module that has all raw image data, as well as metadata. Subsequent analysis in this notebook is restricted to a single experiment, but can be generalized to many experiments as all Experiment objects have the same interface / methods. \n",
    "\n",
    "An Experiment object is essentially a series of .json files that contain metadata which reference the raw images on the database. Therefore they are fairly small in size and can be created and stored locally, ideally in a './experiments/' folder for ease of navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directories to contain experiment files\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "experiment_path = cwd + '/experiments/' + dataset_id + '/'\n",
    "\n",
    "if not os.path.exists(experiment_path):\n",
    "    os.mkdir(experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/napari/__init__.py:27: UserWarning: \n",
      "    napari was tested with QT library `>=5.12.3`.\n",
      "    The version installed is 5.9.6. Please report any issues with this\n",
      "    specific QT version at https://github.com/Napari/napari/issues.\n",
      "    \n",
      "  warn(message=warn_message)\n"
     ]
    }
   ],
   "source": [
    "# To create experiment files we need to find a few key pieces of metadata: positions, and channels \n",
    "# these could be retrieved through the above database queries but InSituToolkit exposes a few useful methods\n",
    "\n",
    "from InSituToolkit.imaging_database import write_experiment, get_positions, get_channels, search_ids\n",
    "from slicedimage import ImageFormat\n",
    "db_credentials = '/Users/andrew.cote/Documents/db_credentials.json' \n",
    "\n",
    "\n",
    "# search the database for dataset id's that contain a certain string\n",
    "set_of_datasets = search_ids(db_credentials, 'GW')\n",
    "\n",
    "# find all the microscope positions for a dataset in the database\n",
    "positions = get_positions(db_credentials, dataset_id)\n",
    "\n",
    "# find the filters and channels used\n",
    "# Note: it is good practice to inspect the channels variable manually to double check we are not mis-assigning channels\n",
    "channels = get_channels(db_credentials, dataset_id)\n",
    "\n",
    "nuc_channel = [channels[0]]\n",
    "stain_channel = [channels[1]]\n",
    "spot_channel = [channels[2], channels[3], channels[4]]\n",
    "\n",
    "# Note: the dataset_id MUST be contained in a list. Multiple dataset ID's could be written to the same experiment\n",
    "# if the channels are common among them. \n",
    "\n",
    "write_experiment(db_credentials, experiment_path, [dataset_id], \n",
    "                spot_channels = spot_channel, \\\n",
    "                nuc_channels = nuc_channel, \\\n",
    "                stain_channels = stain_channel, \\\n",
    "                positions = positions)   # By default the InSituScope saves as .PNG files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL DETOUR: For a larger number of experiments with the same <id>, we could generalize this to:\n",
    "list_of_datasets = []\n",
    "list_of_positions = []\n",
    "list_of_channels = []\n",
    "for dataset_id in search_ids(db_credentials, 'GW'):\n",
    "    list_of_datasets.append(dataset_id)\n",
    "    list_of_positions.append(get_positions(db_credentials, dataset_id))\n",
    "    list_of_channels.append(get_channels(db_credentials, dataset_id))\n",
    "    \n",
    "# ... include the above code for creating directories and experiments (ommitted here for run-ability of this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Starfish Experiment files and viewing images in napari\n",
    "\n",
    "Napari is a viewer that is built around manipulating high-dimensional image files, for example, the 5D image file from a starfish Experiment, where the dimensions are (Round, Channel, Z, X, Y). It also has convenient options for viewing spots, stains, and segmentation masks on top of raw image files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: the below command '%gui qt5' is only required in a jupyter notebook. In a standalone script, starfish.display \n",
    "# will open the napari window by default. \n",
    "\n",
    "%gui qt5\n",
    "from starfish import Experiment, FieldOfView, display\n",
    "\n",
    "exp = Experiment.from_json(experiment_path + 'experiment.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment objects are dicts which hold all the image data for each microscope location, or fov. A likely use-case\n",
    "# is to perform the same image processing technique to all fov's in an experiment. We can collect all keys as:\n",
    "\n",
    "list_of_keys = []\n",
    "\n",
    "for key in exp.keys():\n",
    "    list_of_keys.append(key)\n",
    "\n",
    "# a fov has multiple types of images depending on the data that was uploaded, for example, nuclei, or stain\n",
    "# starfish by default returns a ImageStack Iterator object, which necessitates the call of 'next()' to \n",
    "# retrieve the actual image stack\n",
    "\n",
    "sample_primary = next(exp['fov_002'].get_images('primary'))\n",
    "sample_nuclei = next(exp['fov_002'].get_images('nuclei'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:12<00:00,  2.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:04<00:00,  2.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x1c8e3cbf90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To display multiple images in the same viewer, assign a variable name to the display(ImageStack) command\n",
    "\n",
    "example_viewer = display(sample_primary)\n",
    "display(sample_nuclei, viewer = example_viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Image Processing in Starfish\n",
    "\n",
    "Starfish has numerous built-in methods to do some simple image processing tasks, including:\n",
    "- image registration (learning and applying transforms between successive imaging rounds)\n",
    "- projection (reducing the dimensionality of the images, e.g. flattening the z-stack)\n",
    "- filtering (high-pass or low-pass filtering to help isolate spots)\n",
    "\n",
    "A more detailed list can be found here: https://spacetx-starfish.readthedocs.io/en/stable/api/image/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:13<00:00,  2.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:13<00:00,  2.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:15<00:00,  2.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:13<00:00,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# A common step is to project all images along the z-dimension by the maximum pixel value, as this captures the \n",
    "# information from the best in-focus plane. \n",
    "\n",
    "from starfish.types import Axes, Coordinates, Features, FunctionSource, TraceBuildingStrategies\n",
    "from starfish.image import Filter, LearnTransform, ApplyTransform, Segment\n",
    "\n",
    "projected_z_stacks = []\n",
    "\n",
    "for key in list_of_keys[0:4]:\n",
    "    img_raw = next(exp[key].get_images('primary'))\n",
    "    img_proj_z = img_raw.reduce({Axes.ZPLANE}, func='max')\n",
    "    projected_z_stacks.append(img_proj_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 31.01it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 25.49it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 22.96it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 30.28it/s]\n"
     ]
    }
   ],
   "source": [
    "multi_view = display(projected_z_stacks[0])\n",
    "\n",
    "for stack in projected_z_stacks[1:]:\n",
    "    display(stack, viewer=multi_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<starfish.ImageStack (r: 1, c: 1, z: 11, y: 2048, x: 2048)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenting cells using starfish watershed algorithm\n",
    "\n",
    "Watershed algorithm is a method of segmenting cells based on changes in pixel intensity, by grouping pixels into 'basins'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codebook construction\n",
    "\n",
    "Codebooks associate the information of different colored spots across rounds to specified target genes. They can be used in two ways:\n",
    "\n",
    "- RNAscope: associated spots in each channel with a target gene\n",
    "- InSituSequencing: associate a specific sequence of spots present in different channels with a target gene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starfish import Codebook\n",
    "from starfish.types import Axes, Coordinates, Features\n",
    "\n",
    "# RNAscope codebooks should only have one round value for each target gene, as they are imaged in a single round\n",
    "codebook_RNAscope = [\n",
    "      {\n",
    "          Features.CODEWORD: [\n",
    "              {Axes.ROUND.value: 0, Axes.CH.value: 0, Features.CODE_VALUE: 1},\n",
    "          ],\n",
    "          Features.TARGET: \"example_gene1\"\n",
    "      },\n",
    "      {\n",
    "          Features.CODEWORD: [\n",
    "              {Axes.ROUND.value: 0, Axes.CH.value: 1, Features.CODE_VALUE: 1},\n",
    "          ],\n",
    "          Features.TARGET: \"example_gene2\"\n",
    "      },\n",
    "      {\n",
    "          Features.CODEWORD: [\n",
    "              {Axes.ROUND.value: 0, Axes.CH.value: 2, Features.CODE_VALUE: 1},\n",
    "          ],\n",
    "          Features.TARGET: \"example_gene3\"\n",
    "      },\n",
    "  ]\n",
    "\n",
    "# ISS codebooks will by nature have multiple rounds for each gene, each round corresponds to reading off a single\n",
    "# letter of the barcode. The different letters will appear on different channels and therefore can be repeated in\n",
    "# a single target. Round number refers to position in the sequence and so must be unique for a given target. \n",
    "codebook_ISS = [\n",
    "      {\n",
    "          Features.CODEWORD: [\n",
    "              {Axes.ROUND.value: 0, Axes.CH.value: 0, Features.CODE_VALUE: 1},\n",
    "              {Axes.ROUND.value: 1, Axes.CH.value: 1, Features.CODE_VALUE: 1},\n",
    "              {Axes.ROUND.value: 2, Axes.CH.value: 0, Features.CODE_VALUE: 1},\n",
    "              {Axes.ROUND.value: 3, Axes.CH.value: 2, Features.CODE_VALUE: 1}\n",
    "          ],\n",
    "          Features.TARGET: \"example_gene1\"\n",
    "      },\n",
    "      {\n",
    "          Features.CODEWORD: [\n",
    "              {Axes.ROUND.value: 0, Axes.CH.value: 0, Features.CODE_VALUE: 1},\n",
    "              {Axes.ROUND.value: 1, Axes.CH.value: 1, Features.CODE_VALUE: 1},\n",
    "              {Axes.ROUND.value: 2, Axes.CH.value: 0, Features.CODE_VALUE: 1},\n",
    "              {Axes.ROUND.value: 3, Axes.CH.value: 2, Features.CODE_VALUE: 1}\n",
    "          ],\n",
    "          Features.TARGET: \"example_gene2\"\n",
    "      }\n",
    "  ]\n",
    "\n",
    "# Since this example experiment uses RNA scope, we finish the codebook construction by calling the constructor for \n",
    "# the starfish Codebook object. \n",
    "codebook = Codebook.from_code_array(codebook_RNAscope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
